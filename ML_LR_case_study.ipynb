{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Case Study: House Price Prediction\n",
        "---\n",
        "**Problem statement:**\n",
        "Real Estate company RealEstateML would like to study the house prices in Brookside, VT.\n",
        "\n",
        "RealEstateML provided the following datasets to your team:\n",
        "- house price\n",
        "- school district\n",
        "- population\n",
        "- crime data\n",
        "\n",
        "**Deliverable:**\n",
        "Can you build a Linear Regression model using Python to predict the housing prices in Brookside, VT?\n",
        "*(discovery questions)*\n"
      ],
      "metadata": {
        "id": "Ytu8dqE7oJyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Dictionary\n",
        "\n",
        "house price: `house price.csv`\n",
        "\n",
        "| column | description |\n",
        "| ----------- | ----------- |\n",
        "| House id | house id after anonymization |\n",
        "| House price (k) | House price in US dollars, measured by 1,000 |\n",
        "| size | House size in square feet |\n",
        "| number of bedrooms | Number of bedrooms in this house |\n",
        "| school district | School district this house belongs to |\n",
        "| zip code | The zip code of the house location |\n",
        "\n",
        "school district: `school_district.csv`\n",
        "\n",
        "| column | description |\n",
        "| ----------- | ----------- |\n",
        "| school district | school district id, matches school district in 'house price' |\n",
        "| school rating | Rating from “Great! Schools”, higher score are better |\n",
        "\n",
        "population: `population.csv`\n",
        "\n",
        "| column | description |\n",
        "| ----------- | ----------- |\n",
        "| zip | zip code |\n",
        "| Population(k) | population measured by 1000 |\n",
        "\n",
        "crime data: `crime_data.csv`\n",
        "\n",
        "| column | description |\n",
        "| ----------- | ----------- |\n",
        "| zip code | zip code |\n",
        "| Safety Score (0-10) | higher score indicates less crime in the zip code |\n",
        "\n"
      ],
      "metadata": {
        "id": "VV6c38ZvrQNE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the data"
      ],
      "metadata": {
        "id": "wuQW6utA-9co"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the data (from CSV files on the web)\n",
        "import pandas as pd\n",
        "\n",
        "house_data = pd.read_csv(r'https://raw.githubusercontent.com/odonnell31/linear_regression_ML/main/house_price.csv',\n",
        "                         dtype={'zip code': str})\n",
        "school_data = pd.read_csv(r'https://raw.githubusercontent.com/odonnell31/linear_regression_ML/main/school_district.csv')\n",
        "population_data = pd.read_csv(r'https://raw.githubusercontent.com/odonnell31/linear_regression_ML/main/population.csv',\n",
        "                              dtype={'zip': str})\n",
        "crime_data = pd.read_csv(r'https://raw.githubusercontent.com/odonnell31/linear_regression_ML/main/crime_data.csv',\n",
        "                         dtype={'zip code': str})"
      ],
      "metadata": {
        "id": "8DWauGPwtMON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the shape of each dataframe\n",
        "for dataset in [('house_data', house_data),\n",
        "                ('school_data', school_data),\n",
        "                ('population_data', population_data),\n",
        "                ('crime_data', crime_data)]:\n",
        "  print(f\"{dataset[0]}\")\n",
        "  print(f\"shape: {dataset[1].shape}\")\n",
        "  print(f\"columns: {dataset[1].columns}\")\n",
        "  print(\"-\"*5)"
      ],
      "metadata": {
        "id": "_gEANK21wfhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Email from RealEstateML:\n",
        "Please consider the followings before you start your analysis:\n",
        "- The main goal is to create a prediction model that can estimate a house's price based on the variables we have about that house.\n",
        "- To clarify a few points in the data:\n",
        "  - the zip code 16199 data was accidentally deleted in the population data. The population is 132K.\n",
        "  - S1010 is a simple typo for S10110\n",
        "  - the safety score over 10 is error data and can be replaced by the average\n",
        "  - you can handle missing value as you see fit\n",
        "  - please remove duplicate records\n"
      ],
      "metadata": {
        "id": "ThRiZ01oqgpl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing *(important)*"
      ],
      "metadata": {
        "id": "yFpoZQJ76Ihz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Incorrect values"
      ],
      "metadata": {
        "id": "KsyIMu2Y9cqy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# population_data: add zip code 16199 with population\n",
        "population_data.loc[len(population_data.index)] = ['16199', 132]"
      ],
      "metadata": {
        "id": "cx569oEy8rkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# school_data: fix school district 'S1010'\n",
        "school_data['school district'].replace('S1010', 'S10110', inplace=True)"
      ],
      "metadata": {
        "id": "3e9sibv48use"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# crime_data: set 'Safety Score (0-10)' > 10 to the mean value\n",
        "mean_safety_score = crime_data['Safety Score (0-10)'].mean()\n",
        "crime_data.loc[crime_data['Safety Score (0-10)'] > 10, 'Safety Score (0-10)'] = mean_safety_score"
      ],
      "metadata": {
        "id": "snBWG4dh8xtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How should we handle missing values?"
      ],
      "metadata": {
        "id": "FWemGIZT83eK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# handle missing values\n",
        "for ds in [('house_data', house_data),\n",
        "           ('school_data', school_data),\n",
        "           ('population_data', population_data),\n",
        "           ('crime_data', crime_data)]:\n",
        "  print(f\"dropping {ds[1].shape[0] - ds[1].dropna().shape[0]} rows from {ds[0]} due to missing values\")\n",
        "  ds[1].dropna(inplace=True)"
      ],
      "metadata": {
        "id": "c1174qe08zuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How should we remove duplicate records?"
      ],
      "metadata": {
        "id": "wSyQeGDI8-wV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# remove duplicate records\n",
        "def remove_duplicates(df: pd.DataFrame,\n",
        "                      df_name: str,\n",
        "                      subset_columns: list) -> pd.DataFrame:\n",
        "\n",
        "  num_duplicates = df.duplicated(subset=subset_columns).sum()\n",
        "  print(f\"dropping {num_duplicates} duplicate rows from {df_name}\")\n",
        "  df = df.drop_duplicates(subset=subset_columns)\n",
        "  return df"
      ],
      "metadata": {
        "id": "FMvLHsrS8-96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "house_data = remove_duplicates(df = house_data,\n",
        "                               df_name = \"house_data\",\n",
        "                               subset_columns = ['House id'])\n",
        "\n",
        "school_data = remove_duplicates(df = school_data,\n",
        "                               df_name = \"school_data\",\n",
        "                               subset_columns = ['school district'])\n",
        "\n",
        "population_data = remove_duplicates(df = population_data,\n",
        "                               df_name = \"population_data\",\n",
        "                               subset_columns = ['zip'])\n",
        "\n",
        "crime_data = remove_duplicates(df = crime_data,\n",
        "                               df_name = \"crime_data\",\n",
        "                               subset_columns = ['zip code'])"
      ],
      "metadata": {
        "id": "tD9LinVh9JKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data formatting"
      ],
      "metadata": {
        "id": "P_fK5hFv9OtJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# replace \"k\" columns with actual numerical values\n",
        "pd.options.mode.chained_assignment = None\n",
        "\n",
        "house_data['House price ($)'] = house_data['House price (k)'] * 1000\n",
        "house_data.drop(columns=['House price (k)'], inplace=True)\n",
        "\n",
        "population_data['Population'] = population_data['Population(k)'] * 1000\n",
        "population_data.drop(columns=['Population(k)'], inplace=True)\n",
        "\n",
        "house_data[['House id', 'House price ($)']].sample(3)"
      ],
      "metadata": {
        "id": "gu_bEfa1vixq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Merge and subset the ML dataset"
      ],
      "metadata": {
        "id": "pZSCUlnD6NXd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DbxXW5Vbn59b"
      },
      "outputs": [],
      "source": [
        "ml_data = house_data.merge(school_data,\n",
        "                           how = 'inner',\n",
        "                           on = 'school district')\n",
        "\n",
        "ml_data = ml_data.merge(population_data,\n",
        "                        how = 'inner',\n",
        "                        left_on = 'zip code',\n",
        "                        right_on = 'zip')\n",
        "\n",
        "ml_data = ml_data.merge(crime_data,\n",
        "                        how = 'inner',\n",
        "                        on = 'zip code')\n",
        "\n",
        "print(f'shape of merged ml_data: {ml_data.shape}')\n",
        "ml_data.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory Data Analysis (EDA)"
      ],
      "metadata": {
        "id": "Whpnmf2kFf36"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Variable Distributions and Outliers"
      ],
      "metadata": {
        "id": "3suOoh-eEGQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import needed library\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# define function to plot histogram and identify outliers\n",
        "def plot_histogram(df: pd.DataFrame,\n",
        "                   variable: str,\n",
        "                   bins=10,\n",
        "                   color='grey',\n",
        "                   edgecolor='black',\n",
        "                   figsize=(7, 2)):\n",
        "\n",
        "    # set the figure size\n",
        "    plt.figure(figsize=figsize)\n",
        "\n",
        "    # plot the histogram\n",
        "    plt.hist(df[variable],\n",
        "             bins=bins,\n",
        "             color=color,\n",
        "             edgecolor=edgecolor)\n",
        "\n",
        "    # customize the plot labels and colors\n",
        "    plt.title(f'{variable} Histogram')\n",
        "    plt.xlabel(f'{variable}')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.ticklabel_format(style='plain', axis='x')\n",
        "    plt.grid(True)\n",
        "\n",
        "    # define the Inter Quartile Range (iqr) and outlier bounds\n",
        "    q1 = df[variable].quantile(0.25)\n",
        "    q3 = df[variable].quantile(0.75)\n",
        "    iqr = q3 - q1\n",
        "    lower_bound = q1 - 1.5 * iqr\n",
        "    upper_bound = q3 + 1.5 * iqr\n",
        "\n",
        "    # mark the outlier boundson the histogram\n",
        "    plt.axvline(lower_bound, color='blue', linestyle='dashed', linewidth=2, label='Lower Bound')\n",
        "    plt.axvline(upper_bound, color='blue', linestyle='dashed', linewidth=2, label='Upper Bound')\n",
        "\n",
        "    # Show the plot\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # count the outliers\n",
        "    num_outliers = ((df[variable] < lower_bound) | (df[variable] > upper_bound)).sum()\n",
        "\n",
        "    # print information about outliers\n",
        "    if num_outliers > 0:\n",
        "        print(f\"{num_outliers} potential outliers detected in {variable} distribution\")\n",
        "        print(f\"Lower Bound: {lower_bound}, Upper Bound: {upper_bound}\")\n",
        "    else:\n",
        "        print(f\"no potential outliers detected in {variable} distribution\")\n",
        "        print(f\"Lower Bound: {lower_bound}, Upper Bound: {upper_bound}\")\n",
        "\n",
        "    # print a new line\n",
        "    print(\"\"\"\n",
        "          -----\n",
        "          \"\"\")"
      ],
      "metadata": {
        "id": "6gW4ItbSQ3gI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# look at histograms for each of your variables\n",
        "for v in ['size', 'number of bedrooms', 'school rating',\n",
        "          'Safety Score (0-10)', 'Population', 'House price ($)']:\n",
        "  plot_histogram(df = ml_data,\n",
        "                 variable = v,\n",
        "                 bins = 10)"
      ],
      "metadata": {
        "id": "clOcMXjSO_ps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Collinearity"
      ],
      "metadata": {
        "id": "wwhFty-WGCrY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# create a correlation matrix\n",
        "corr_matrix = ml_data[['size', 'number of bedrooms',\n",
        "                       'school rating', 'Safety Score (0-10)',\n",
        "                       'Population']].corr()\n",
        "\n",
        "# create a heatmap from the corr matrix\n",
        "sns.set(style=\"white\")\n",
        "plt.figure(figsize=(7, 3))\n",
        "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
        "sns.heatmap(corr_matrix,\n",
        "            annot=True,\n",
        "            cmap='coolwarm',\n",
        "            fmt=\".2f\",\n",
        "            linewidths=.5,\n",
        "            mask=mask,\n",
        "            vmin=-1, vmax=1)\n",
        "\n",
        "# customize the output and show the plot\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.title('Feature Correlation Heatmap')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VkFMy3ekPD3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear relationships (Pearson correlation coefficient)\n",
        "Pearson's correlation coefficient is a statistical measure that focuses on quantifying the linear relationship between two continuous variables. Calculated by dividing the covariance of the two variables by the product of their standard deviations, the coefficient ranges from -1 to 1. A value of -1 indicates a perfect negative linear relationship, 1 indicates a perfect positive linear relationship, and 0 indicates no linear relationship. In the context of linear regression, the Pearson coefficient is employed to assess the linear relationships between independent and dependent variables."
      ],
      "metadata": {
        "id": "sUPknZERGFYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "# create an empty dataframe\n",
        "correlation_df = pd.DataFrame(columns=['Feature', 'Statistic', 'P-value'])\n",
        "\n",
        "# loop through each feature to get the pearson coefficient\n",
        "for feature in ['size', 'number of bedrooms', 'school rating', 'Safety Score (0-10)', 'Population']:\n",
        "    pearson_result = pearsonr(ml_data[feature], ml_data['House price ($)'])\n",
        "\n",
        "    # append the result to the dataframe\n",
        "    correlation_df.loc[len(correlation_df.index)] = [feature,\n",
        "                                                     round(pearson_result[0], 5),\n",
        "                                                     round(pearson_result[1], 5)]\n",
        "\n",
        "# display the dataframe\n",
        "correlation_df"
      ],
      "metadata": {
        "id": "wjHFqpClQ06b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fit your ML Model"
      ],
      "metadata": {
        "id": "mpUz4TPdGWvf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define your features and target variable"
      ],
      "metadata": {
        "id": "VBtkVU5CNDIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = ml_data[['size', 'number of bedrooms', 'school rating',\n",
        "             'Safety Score (0-10)', 'Population']]\n",
        "y = ml_data['House price ($)']"
      ],
      "metadata": {
        "id": "DvhbPHmNfaJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split your data into training and testing sets"
      ],
      "metadata": {
        "id": "gjSc0UvFNlk4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.25,\n",
        "                                                    random_state=31)\n",
        "\n",
        "print(f'size of training data: {X_train.shape}')\n",
        "print(f'size of testing data: {X_test.shape}')"
      ],
      "metadata": {
        "id": "B-svuui4Nrmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fit your Linear Regression Model"
      ],
      "metadata": {
        "id": "rOgOPIsiOLT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import linear_model\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "#create the model\n",
        "LR_model = linear_model.LinearRegression()\n",
        "\n",
        "# fit your model on the training data\n",
        "LR_model.fit(X_train, y_train)\n",
        "\n",
        "# make predictions using the testing set\n",
        "y_pred = LR_model.predict(X_test)"
      ],
      "metadata": {
        "id": "PhxmGgIVOU2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation your ML Model"
      ],
      "metadata": {
        "id": "qhXrhOYUGbtF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Print Evaluation Metrics\n",
        "- **R Squared:** The % of the variability in the dependent variable that is explained by the independent variables, ranges from 0-1. 1 is the best.\n",
        "- **Root Mean Squared Error (RMSE):** the measure of the average magnitude of the errors between predicted and observed values in a regression model. It is calculated by taking the square root of the mean of the squared differences between predicted and actual values."
      ],
      "metadata": {
        "id": "sMbSGCPpOeP7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# calculate R squared\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f'R squared: {round(r2, 5)}')\n",
        "\n",
        "# calculate RMSE\n",
        "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "print(f'Root Mean Squared Error (RMSE): {round(rmse, 2)}')"
      ],
      "metadata": {
        "id": "mrSVEFXTOiJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot Evaluation visualzations"
      ],
      "metadata": {
        "id": "MeD2u5N5Olzo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# scatter plot to show actual value vs the models predicted value\n",
        "# (y actual vs y predicted)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# plot the points on a scatter plot\n",
        "plt.scatter(y_test, y_pred,\n",
        "            alpha=0.2, label='Actual vs. Predicted')\n",
        "\n",
        "# plot a line that represents perfectly accurate predictions\n",
        "plt.plot([min(y_test), max(y_test)],\n",
        "         [min(y_test), max(y_test)],\n",
        "         color='red', linestyle='--',\n",
        "         label='Perfect Accuracy')\n",
        "\n",
        "# customize the plot\n",
        "plt.title('Actual vs. Predicted Values')\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jc407I33S6u9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Improve your ML Model\n",
        "- Try removing features from the models\n",
        "- Try different ways to draw your regression line, like L1 regression (https://scikit-learn.org/stable/modules/linear_model.html#)"
      ],
      "metadata": {
        "id": "pHxORpv_Gf4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# improve your model here"
      ],
      "metadata": {
        "id": "E29fcn7EOsl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deliver your ML Model to RealEstateML\n",
        "- after you're satisfied with your models results, deliver the following to RealEstateML\n",
        "  - a summary of your model: features used, evaluation metrics, plot of predictions vs actuals\n",
        "  - a python file to implement your model from beginning to end\n",
        "  - a CSV that shows your models predictions on the testing dataset\n",
        "  - some ideas for enhancing the model, like additional data points, other evaluation metrics, different supervised ML algorithms, etc"
      ],
      "metadata": {
        "id": "fymnAZlaGm_s"
      }
    }
  ]
}